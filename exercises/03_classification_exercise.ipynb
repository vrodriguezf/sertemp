{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3. Time series classification - exercise\n",
    "\n",
    "> Try your best in one of the UCR datasets!\n",
    "\n",
    "Today you'll apply the knowledge acquired in part 3 to classify one of the datasets\n",
    "from the popular UCR archive for time series classification (TSC). You don't have \n",
    "to build the TSC algorithm from scratch if you don't want to, but rather make use\n",
    "of high level tools, such as:\n",
    "- [aeon](https://github.com/aeon-toolkit/aeon): Implements every kind of TSC algorithm \n",
    "covered in this course (distance-based, dictionary-based, deep learning based, \n",
    "rocket-based...). It is compatible with scikit learn.\n",
    "- [tsai](https://github.com/timeseriesAI/tsai): Implements many deep neural architectures\n",
    "for TSC, beyond InceptionTime (e.g. Transformers for time series). It also has a\n",
    "fast implementation of ROCKET-based algorithms. It is built on top of fastai (which\n",
    "in turn is built on top of Pytorch)\n",
    "- [tslearn](https://github.com/tslearn-team/tslearn#available-features): Compatible\n",
    "with scikit-learn.\n",
    "- [sk-time](https://github.com/sktime/sktime). Impklements multiple TSC algorithms,\n",
    "including all of the ones seen in this course\n",
    "\n",
    "The data we will use in this session comes from The City of Melbourne, Australia. They have developed an \n",
    "automated pedestrian counting system to better understand pedestrian activity \n",
    "within the municipality, such as how people use different city locations at \n",
    "different time of the day. Their objective is to analyse this data in order to \n",
    "facilitate decision making and urban planning for the future. To see an interactive\n",
    "webapp with the pedestrianconting system in action, check it out [here](https://www.pedestrian.melbourne.vic.gov.au/#date=11-06-2018&time=4). \n",
    "\n",
    "To create a TSC dataset out of this experiment, time series researchers have \n",
    "extracted data of 10 locations for the whole year 2017. The series represent\n",
    "pedestrian count for 12 months of the year 2017. Classes correspond location of sensor placement: \n",
    "- Class 1: Bourke Street Mall (North) \n",
    "- Class 2: Southern Cross Station \n",
    "- Class 3: New Quay \n",
    "- Class 4: Flinders St Station Underpass \n",
    "- Class 5: QV Market-Elizabeth (West) \n",
    "- Class 6: Convention/Exhibition Centre \n",
    "- Class 7: Chinatown-Swanston St (North) \n",
    "- Class 8: Webb Bridge \n",
    "- Class 9: Tin Alley-Swanston St (West) \n",
    "- Class 10: Southbank \n",
    "\n",
    "There is nothing to infer from the order of examples in the train and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/victor/.fastai/data/MelbournePedestrian\n"
     ]
    }
   ],
   "source": [
    "from fastai.data.external import untar_data\n",
    "\n",
    "path = untar_data('https://timeseriesclassification.com/aeon-toolkit/MelbournePedestrian.zip')\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#13) [Path('/home/victor/.fastai/data/MelbournePedestrian/README.md'),Path('/home/victor/.fastai/data/MelbournePedestrian/MelbournePedestrian_TEST.txt'),Path('/home/victor/.fastai/data/MelbournePedestrian/MelbournePedestrian.txt'),Path('/home/victor/.fastai/data/MelbournePedestrian/MelbournePedestrian_TEST.arff'),Path('/home/victor/.fastai/data/MelbournePedestrian/MelbournePedestrian_TRAIN.ts'),Path('/home/victor/.fastai/data/MelbournePedestrian/MelbournePedestrian_nmv_TEST.arff'),Path('/home/victor/.fastai/data/MelbournePedestrian/MelbournePedestrian_TRAIN.txt'),Path('/home/victor/.fastai/data/MelbournePedestrian/MelbournePedestrian_nmv_TEST.ts'),Path('/home/victor/.fastai/data/MelbournePedestrian/MelbournePedestrian_TRAIN.arff'),Path('/home/victor/.fastai/data/MelbournePedestrian/MelbournePedestrian_TEST.csv')...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files `MelbournePedestrian_TRAIN.txt` and `MelbournePedestrian_TEST.txt` contain\n",
    "the hourly-based pedestrian counts for each of the locations, 1 row per day (24 hours). \n",
    "```\n",
    "1.0000000e+00   9.7000000e+01   4.2000000e+01   2.0000000e+01   1.0000000e+01   1.4000000e+01   3.3000000e+01   1.1300000e+02   4.2200000e+02   8.7500000e+02   1.0030000e+03   1.3510000e+03   1.6130000e+03   2.9370000e+03   2.9540000e+03   2.1670000e+03   2.3300000e+03   2.1910000e+03   2.6210000e+03   2.4000000e+03   1.8920000e+03   1.2530000e+03   8.4400000e+02   4.3800000e+02   2.0400000e+02\n",
    "```\n",
    "In the example above, the first number represents the class (1 in this case), and\n",
    "the rest 24 numbers are the pedestrian count at every hour of the day.\n",
    "\n",
    "From now on, you'll be in charge of loading the data, preprocessing and visualising it, \n",
    "splitting the training set into train/valid sets if needed, and of course, run whatever TSC\n",
    "algorithm you choose and compare them. \n",
    "\n",
    "You can also add covariates to the dataset, i.e., auxiliary variables that make the\n",
    "data multivariate and can help the model understand better the patterns \n",
    "(e.g., hour of the day, rolling mean, ...)\n",
    "\n",
    "To evaluate the results on the test set, you can use any classic classification \n",
    "metric, such as the accuracy, the F1 (multiclass), precision, or recall. Also, \n",
    "have a look at the confusion matrix, and plot the samples that are misclassified \n",
    "with a higher error, to see if you find patterns in they way the model fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
