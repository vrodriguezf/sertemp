{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance-based time series classification algorithms\n",
    "Import the necessary libraries, including pandas, numpy, matplotlib, and sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pandas for data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Importing numpy for numerical computing\n",
    "import numpy as np\n",
    "\n",
    "# Importing matplotlib for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing sklearn for machine learning and data mining\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess Time Series Data\n",
    "Load the time series data and perform necessary preprocessing steps such as normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the time series data\n",
    "# Assuming the data is in a CSV file named 'time_series_data.csv'\n",
    "data = pd.read_csv('time_series_data.csv')\n",
    "\n",
    "# Display the first few rows of the data\n",
    "print(data.head())\n",
    "\n",
    "# Preprocess the data\n",
    "# Normalize the features to a range between 0 and 1\n",
    "# Assuming the last column is the target variable and the rest are features\n",
    "features = data.columns[:-1]\n",
    "data[features] = preprocessing.MinMaxScaler().fit_transform(data[features])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# Assuming the last column is the target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data[data.columns[-1]], test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the first few rows of the preprocessed data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Time Series Data\n",
    "Use matplotlib to visualize the time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the first time series in the training set\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(X_train.iloc[0])\n",
    "plt.title('First Time Series in the Training Set')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Normalized Value')\n",
    "plt.show()\n",
    "\n",
    "# Plotting the mean time series\n",
    "mean_time_series = X_train.mean()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(mean_time_series)\n",
    "plt.title('Mean Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Normalized Value')\n",
    "plt.show()\n",
    "\n",
    "# Plotting the standard deviation of the time series\n",
    "std_time_series = X_train.std()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(std_time_series)\n",
    "plt.title('Standard Deviation of Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Normalized Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Distance Between Time Series\n",
    "Compute the distance between time series using a suitable distance measure such as Euclidean or Dynamic Time Warping (DTW)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "# Function to compute Euclidean distance\n",
    "def compute_euclidean_distance(ts1, ts2):\n",
    "    return euclidean(ts1, ts2)\n",
    "\n",
    "# Function to compute Dynamic Time Warping distance\n",
    "def compute_dtw_distance(ts1, ts2):\n",
    "    distance, path = fastdtw(ts1, ts2, dist=euclidean)\n",
    "    return distance\n",
    "\n",
    "# Compute the Euclidean distance between the first two time series in the training set\n",
    "euclidean_distance = compute_euclidean_distance(X_train.iloc[0], X_train.iloc[1])\n",
    "print('Euclidean distance: ', euclidean_distance)\n",
    "\n",
    "# Compute the Dynamic Time Warping distance between the first two time series in the training set\n",
    "dtw_distance = compute_dtw_distance(X_train.iloc[0], X_train.iloc[1])\n",
    "print('DTW distance: ', dtw_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement k-Nearest Neighbors (k-NN) Classifier\n",
    "Implement the k-NN classifier using the computed distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the k-NN classifier\n",
    "class KNNClassifier:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    # Function to fit the model\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    # Function to predict the class labels\n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for i in range(len(X_test)):\n",
    "            distances = []\n",
    "            for j in range(len(self.X_train)):\n",
    "                # Compute the distance between the test instance and each training instance\n",
    "                distance = compute_dtw_distance(X_test.iloc[i], self.X_train.iloc[j])\n",
    "                distances.append((self.y_train.iloc[j], distance))\n",
    "            # Sort the distances in ascending order\n",
    "            distances.sort(key=lambda x: x[1])\n",
    "            # Get the class labels of the k nearest neighbors\n",
    "            neighbors = [distances[m][0] for m in range(self.k)]\n",
    "            # Predict the class label by majority vote\n",
    "            predictions.append(max(set(neighbors), key=neighbors.count))\n",
    "        return predictions\n",
    "\n",
    "# Create an instance of the k-NN classifier\n",
    "knn = KNNClassifier(k=3)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the class labels for the test data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the accuracy score\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Classifier Performance\n",
    "Evaluate the performance of the classifier using appropriate metrics such as accuracy, precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries for performance evaluation\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Compute the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# Compute the precision\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(\"Precision: \", precision)\n",
    "\n",
    "# Compute the recall\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print(\"Recall: \", recall)\n",
    "\n",
    "# Compute the F1 score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1 Score: \", f1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
